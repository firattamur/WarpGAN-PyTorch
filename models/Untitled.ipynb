{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7396b829",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa57ddab",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (Temp/ipykernel_13820/2469161808.py, line 85)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\2PKNX2\\AppData\\Local\\Temp/ipykernel_13820/2469161808.py\"\u001b[1;36m, line \u001b[1;32m85\u001b[0m\n\u001b[1;33m    if x is None:\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as tf\n",
    "from torch.nn.modules.activation import ReLU\n",
    "\n",
    "\n",
    "from .helpers.conv2d import Conv2d\n",
    "\n",
    "\n",
    "class StyleController(nn.Module):\n",
    "    \"\"\"\n",
    "    \n",
    "    Style Controller network.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, batch_size: int, input_size = 8):\n",
    "        \"\"\"\n",
    "        \n",
    "        Style Controller Network\n",
    "        :param batch_size      : number of examples in a batch\n",
    "        :param input_size      : dimension of the style vectors\n",
    "        \n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.batch_size = batch_size\n",
    "        # Used in output channel calculations\n",
    "        # Authors of the paper set it to 64 \n",
    "        self.k = 64\n",
    "\n",
    "        # inp: (in_batch, input_size)\n",
    "        # out: (in_batch, 128)\n",
    "        self.fc1 = nn.Linear(self.input_size, 128, bias = True)\n",
    "        self.initialize_weights_with_he_biases_with_zero(self.fc1)\n",
    "        \n",
    "        # inp: (in_batch, 128)\n",
    "        # out: (in_batch, 128)\n",
    "        self.ln1 = nn.LayerNorm(128)\n",
    "        \n",
    "        # inp: (in_batch, 128)\n",
    "        # out: (in_batch, 128)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        # inp: (in_batch, 128)\n",
    "        # out: (in_batch, 128)\n",
    "        self.fc2 = nn.Linear(128, 128, bias = True)\n",
    "        self.initialize_weights_with_he_biases_with_zero(self.fc2)\n",
    "        \n",
    "        # inp: (in_batch, 128)\n",
    "        # out: (in_batch, 128)\n",
    "        self.ln2 = nn.LayerNorm(128)\n",
    "        \n",
    "        # inp: (in_batch, 128)\n",
    "        # out: (in_batch, 128)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        # inp: (in_batch, 128)\n",
    "        # out: (in_batch, 4 * k)\n",
    "        self.fc3 = nn.Linear(128, 4 * self.k, bias = True)\n",
    "        self.initialize_weights_with_he_biases_with_zero(self.fc3) \n",
    "        \n",
    "        # inp: (in_batch, 128)\n",
    "        # out: (in_batch, 4 * k)\n",
    "        self.fc4 = nn.Linear(128, 4 * self.k, bias = True)\n",
    "        self.initialize_weights_with_he_biases_with_zero(self.fc4)\n",
    "\n",
    "        \n",
    "    def forward(self, x) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        \n",
    "        Forward function for Style Controller.\n",
    "        Returns two concatenated (batch_size, 1, 1, 4 * k) shaped tensors, gamma and beta coefficients\n",
    "        \n",
    "        :param x: style encodings\n",
    "            :shape: (batch_size, input_size)\n",
    "        :return : out\n",
    "            :shape: (batch_size, 2, 1, 4 * k)\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        def forward(self, x):\n",
    "        \n",
    "        if x is None:\n",
    "            x = torch.randn((self.batch_size, self.input_size))\n",
    "        \n",
    "        # inp: (batch_size, input_size)\n",
    "        # out: (batch_size, 128)\n",
    "        x = self.fc1(x)\n",
    "        x = self.ln1(x)\n",
    "        x = self.relu1(x)\n",
    "        \n",
    "        # inp: (batch_size, 128)\n",
    "        # out: (batch_size, 128)\n",
    "        x = self.fc2(x)\n",
    "        x = self.ln2(x)\n",
    "        x = self.relu2(x)\n",
    "        \n",
    "        # inp: (batch_size, 128)\n",
    "        # out: (batch_size, 1, 1, 4 * k)\n",
    "        gamma = self.fc3(x)\n",
    "        gamma = torch.reshape(gamma, [-1, 1, 1, 4 * self.k])\n",
    "        \n",
    "        # inp: (batch_size, 128)\n",
    "        # out: (batch_size, 1, 1, 4 * k)\n",
    "        beta = self.fc4(x)\n",
    "        beta = torch.reshape(beta, [-1, 1, 1, 4 * self.k])\n",
    "        \n",
    "        return torch.cat((beta, gamma), 0)\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c42e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, in_channels, style_controller):\n",
    "         \n",
    "        super().__init__()\n",
    "        \n",
    "        self.style_controller = style_controller \n",
    "        self.k = self.style_controller.k\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels = in_channels, out_channels = 4 * self.k, kernel_size=3)\n",
    "        self.initialize_weights_and_biases(self.conv1)\n",
    "        \n",
    "        self.instance_norm_layer1 = nn.InstanceNorm2d(4 * self.k)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels = 4 * self.k, out_channels = 4 * self.k, kernel_size = 3, bias = False)\n",
    "        nn.init.kaiming_normal_(self.conv2.weight)\n",
    "        \n",
    "        self.instance_norm_layer2 = nn.InstanceNorm2d(4 * self.k)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels = 4 * self.k, out_channels = 4 * self.k, kernel_size = 3)\n",
    "        self.initialize_weights_and_biases(self.conv3)\n",
    "        \n",
    "        self.instance_norm_layer3 = nn.InstanceNorm2d(4 * self.k)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(in_channels = 4 * self.k, out_channels = 4 * self.k, kernel_size = 3, bias = False)\n",
    "        nn.init.kaiming_normal_(self.conv4.weight)\n",
    "        \n",
    "        self.instance_norm_layer4 = nn.InstanceNorm2d(4 * self.k)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(in_channels = 4 * self.k, out_channels = 4 * self.k, kernel_size = 3)\n",
    "        self.initialize_weights_and_biases(self.conv5)\n",
    "        \n",
    "        self.instance_norm_layer5 = nn.InstanceNorm2d(4 * self.k)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        self.conv6 = nn.Conv2d(in_channels = 4 * self.k, out_channels = 4 * self.k, kernel_size = 3, bias = False)\n",
    "        nn.init.kaiming_normal_(self.conv6.weight)\n",
    "        \n",
    "        self.instance_norm_layer6 = nn.InstanceNorm2d(4 * self.k)\n",
    "        \n",
    "        self.conv7 = nn.Conv2d(in_channels = 4 * self.k, out_channels = 4 * self.k, kernel_size = 5)\n",
    "        self.initialize_weights_and_biases(self.conv7)\n",
    "        \n",
    "        self.instance_norm_layer7 = nn.InstanceNorm2d(2 * self.k)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        \n",
    "        self.conv8 = nn.Conv2d(2 * self.k, self.k, 5)\n",
    "        self.initialize_weights_and_biases(self.conv8)\n",
    "        \n",
    "        self.instance_norm_layer8 = nn.InstanceNorm2d(self.k)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        \n",
    "        self.conv9 = nn.Conv2d(self.k, 3, 7)\n",
    "        self.initialize_weights_and_biases(self.conv9, True)\n",
    "        \n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    \n",
    "    def initialize_weights_and_biases(self, layer : nn.Module, bothWeightAndBias = False):\n",
    "        if not bothWeightAndBias:\n",
    "            nn.init.kaiming_normal_(layer.weight)\n",
    "            layer.bias.data.fill_(0.0)\n",
    "        else:\n",
    "            layer.weight.data.fill_(0.0)\n",
    "            layer.bias.data.fill_(0.0)\n",
    "            \n",
    "    def forward(self, styles, x):\n",
    "        style_controller_res = self.style_controller.forward(styles)\n",
    "        gamma = style_controller_res[0:self.style_controller.batch_size, :, :, :]\n",
    "        beta = style_controller_res[self.style_controller.batch_size :, :, :, :]\n",
    "        \n",
    "        print(\"X shape after padding: \", padding2(x, 1, pad_mode=\"zero\").shape)\n",
    "        x_ = self.conv1(padding2(x, 1, pad_mode=\"zero\"))\n",
    "        print(\"X shape after conv: \", x_.shape)\n",
    "        x_ = self.instance_norm_layer1(x_)\n",
    "        print(\"X shape after instance norm: \", x_.shape)\n",
    "        x_ = gamma * x_ + beta\n",
    "        print(\"2: \", x_.shape)\n",
    "        x_ = self.relu1(x_)\n",
    "        \n",
    "        print(self.instance_norm_layer2(self.conv2(padding2(x_, 1, pad_mode=\"zero\"))).shape)\n",
    "        print(x.shape)\n",
    "        x += self.instance_norm_layer2(self.conv2(padding2(x_, 1, pad_mode=\"zero\")))\n",
    "        \n",
    "        print('module res{} shape:'.format(1), [dim for dim in x.shape])\n",
    "        \n",
    "        x = padding2(x, 1, pad_mode=\"zero\")\n",
    "        x_ = self.conv3(x)\n",
    "        x_ = self.instance_norm_layer3(x_)\n",
    "        x_ = gamma * x_ + beta\n",
    "        x_ = self.relu2(x_)\n",
    "        \n",
    "        x_ = padding2(x_, 1, pad_mode=\"zero\")\n",
    "        x += self.instance_norm_layer4(self.conv4(x_))\n",
    "        \n",
    "        print('module res{} shape:'.format(2), [dim for dim in x.shape])\n",
    "        \n",
    "        x = padding2(x, 1, pad_mode=\"zero\")\n",
    "        x_ = self.conv5(x)\n",
    "        x_ = self.instance_norm_layer5(x_)\n",
    "        print(\"Gmma shape: \", gamma.shape)\n",
    "        x_ = gamma * x_ + beta\n",
    "        x_ = self.relu3(x_)\n",
    "        \n",
    "        x_ = padding2(x_, 1, pad_mode=\"zero\")\n",
    "        x += self.instance_norm_layer6(self.conv6(x_))\n",
    "        \n",
    "        print('module res{} shape:'.format(3), [dim for dim in x.shape])\n",
    "        \n",
    "        x = upscale2d(x, 2, pad_mode=\"zero\")\n",
    "        x = padding2(x, 2)\n",
    "        x = self.conv7(x)\n",
    "        x = self.instance_norm_layer7(x)\n",
    "        x = self.relu4(x)\n",
    "        \n",
    "        print('module deconv1 shape:', [dim for dim in x.shape])\n",
    "\n",
    "        x = upscale2d(x, 2)\n",
    "        x = padding2(x, 2, pad_mode=\"zero\")\n",
    "        x = self.conv8(x)\n",
    "        x = self.instance_norm_layer8(x)\n",
    "        x = self.relu5(x)\n",
    "        \n",
    "        x = padding2(x, 3, pad_mode=\"zero\")\n",
    "        x = self.conv9(x)\n",
    "        return self.tanh(x)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbd35c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "controller = StyleController(10,8)\n",
    "styles = torch.tensor(np.ones((10, 8), dtype=float)).float()\n",
    "decoder = Decoder(256, controller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1742df43",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder.forward(styles, torch.tensor(np.ones((10, 256, 256, 256))).float())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
